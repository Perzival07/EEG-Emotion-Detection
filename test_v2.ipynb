{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33a108cc",
   "metadata": {},
   "source": [
    "### New GPU Memory Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8498a405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 05:24:29.144045: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory growth configured for 1 device(s).\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 0. GPU Configuration (NEW)\n",
    "# ==============================================================================\n",
    "# Configure TensorFlow to grow GPU memory usage as needed. This can help prevent\n",
    "# out-of-memory errors on some systems.\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU memory growth configured for {len(gpus)} device(s).\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0fb114",
   "metadata": {},
   "source": [
    "### Dependencies & Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5e4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. Importing Dependencies & Configuration\n",
    "# ==============================================================================\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "# Keras and TensorFlow Layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, Reshape, Bidirectional, LSTM, Dropout, Dense,\n",
    "    TimeDistributed, GlobalAveragePooling1D, concatenate, Layer\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "# Scikit-learn for data splitting and class weights\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    _HAVE_SKLEARN = True\n",
    "except ImportError:\n",
    "    _HAVE_SKLEARN = False\n",
    "\n",
    "# --- Global Constants ---\n",
    "CLASS_NAMES = [\n",
    "    'happy', 'sad', 'surprised', 'satisfied',\n",
    "    'protected', 'frightened', 'angry', 'unconcerned'\n",
    "]\n",
    "\n",
    "FOLDER_TO_CLASS = {\n",
    "    'Happy': 'happy',\n",
    "    'Sad': 'sad',\n",
    "    'Surprise': 'surprised',\n",
    "    'Satisfied': 'satisfied',\n",
    "    'Protected': 'protected',\n",
    "    'Frightened': 'frightened',\n",
    "    'Angry': 'angry',\n",
    "    'Unconcerned': 'unconcerned'\n",
    "}\n",
    "\n",
    "# The 14 main EEG channels to be used from the CSV files\n",
    "EEG_CHANNELS = [\n",
    "    'EEG.AF3', 'EEG.F7', 'EEG.F3', 'EEG.FC5', 'EEG.T7', 'EEG.P7', 'EEG.O1',\n",
    "    'EEG.O2', 'EEG.P8', 'EEG.T8', 'EEG.FC6', 'EEG.F4', 'EEG.F8', 'EEG.AF4'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ce6e7",
   "metadata": {},
   "source": [
    "### Data Preprocessing & Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0ff651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. Data Loading and Preprocessing Functions (Corrected for Sample Weights)\n",
    "# ==============================================================================\n",
    "\n",
    "def wavelet_denoise(data, wavelet='db4', level=4):\n",
    "    \"\"\"Applies wavelet denoising to a 1D signal.\"\"\"\n",
    "    coeffs = pywt.wavedec(data, wavelet, level=level)\n",
    "    sigma = np.median(np.abs(coeffs[-1] - np.median(coeffs[-1]))) / 0.6745\n",
    "    threshold = sigma * np.sqrt(2 * np.log(len(data)))\n",
    "    new_coeffs = coeffs.copy()\n",
    "    for i in range(1, len(coeffs)):\n",
    "        new_coeffs[i] = pywt.threshold(coeffs[i], value=threshold, mode='soft')\n",
    "    reconstructed_signal = pywt.waverec(new_coeffs, wavelet)\n",
    "    return reconstructed_signal[:len(data)]\n",
    "\n",
    "def _read_and_denoise_csv(filepath: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reads a CSV file, applies wavelet denoising to EEG channels,\n",
    "    and returns a NumPy array of all numeric columns.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath, skiprows=1, low_memory=False)\n",
    "    for channel in EEG_CHANNELS:\n",
    "        if channel in df.columns:\n",
    "            signal = df[channel].dropna().values\n",
    "            if np.var(signal) > 0:\n",
    "                denoised_signal = wavelet_denoise(signal)\n",
    "                df.loc[:len(denoised_signal)-1, channel] = denoised_signal\n",
    "    numeric_df = df.select_dtypes(include=[np.number]).copy().fillna(0)\n",
    "    arr = numeric_df.values.astype(np.float32)\n",
    "    return arr[:, None] if arr.ndim == 1 else arr\n",
    "\n",
    "def _ensure_shape_and_resample(raw: np.ndarray, time_steps: int, channels: int, features: int) -> np.ndarray:\n",
    "    \"\"\"Ensure the data has the correct shape by padding or truncating.\"\"\"\n",
    "    flat = raw.flatten()\n",
    "    needed = time_steps * channels * features\n",
    "    if flat.size >= needed:\n",
    "        flat = flat[:needed]\n",
    "    else:\n",
    "        pad = np.zeros(needed - flat.size, dtype=flat.dtype)\n",
    "        flat = np.concatenate([flat, pad], axis=0)\n",
    "    return flat.reshape((time_steps, channels, features))\n",
    "\n",
    "def _normalize_per_sample(sample: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Normalize each sample by subtracting mean and dividing by standard deviation.\"\"\"\n",
    "    mean = sample.mean(axis=0, keepdims=True)\n",
    "    std = sample.std(axis=0, keepdims=True)\n",
    "    std[std < 1e-8] = 1.0\n",
    "    return (sample - mean) / std\n",
    "\n",
    "def load_eeg_dataset(\n",
    "    data_dir: str, time_steps: int, channels: int, features: int,\n",
    "    stressed_classes: Optional[List[str]] = None, test_size: float = 0.15,\n",
    "    val_size: float = 0.15, random_state: int = 42, batch_size: int = 4\n",
    ") -> Tuple[Dict[str, tf.data.Dataset], Dict]:\n",
    "    \"\"\"Load EEG dataset with sample weights included directly.\"\"\"\n",
    "    if not _HAVE_SKLEARN:\n",
    "        raise ImportError(\"Scikit-learn is required. Please run 'pip install scikit-learn'.\")\n",
    "\n",
    "    if stressed_classes is None: stressed_classes = ['frightened', 'angry']\n",
    "    files, labels = [], []\n",
    "    for folder, cls in FOLDER_TO_CLASS.items():\n",
    "        cls_folder = os.path.join(data_dir, folder)\n",
    "        if os.path.isdir(cls_folder):\n",
    "            found = glob.glob(os.path.join(cls_folder, \"*.csv\"))\n",
    "            files.extend(found)\n",
    "            labels.extend([cls] * len(found))\n",
    "\n",
    "    if not files: raise ValueError(f\"No CSV files found in subdirectories of {data_dir}.\")\n",
    "\n",
    "    X_list, y_multi_idx, y_binary = [], [], []\n",
    "    for fpath, cls in zip(files, labels):\n",
    "        raw = _read_and_denoise_csv(fpath)\n",
    "        sample = _ensure_shape_and_resample(raw, time_steps, channels, features)\n",
    "        sample = _normalize_per_sample(sample)\n",
    "        X_list.append(sample.astype(np.float32))\n",
    "        y_multi_idx.append(CLASS_NAMES.index(cls))\n",
    "        y_binary.append(1 if cls in stressed_classes else 0)\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y_multi_idx = np.array(y_multi_idx, dtype=np.int32)\n",
    "    y_binary = np.array(y_binary, dtype=np.float32)\n",
    "    y_multi_onehot = tf.keras.utils.to_categorical(y_multi_idx, num_classes=len(CLASS_NAMES))\n",
    "    \n",
    "    weights = compute_class_weight('balanced', classes=np.arange(len(CLASS_NAMES)), y=y_multi_idx)\n",
    "    class_weights = {i: float(w) for i, w in enumerate(weights)}\n",
    "    \n",
    "    # *** FIX IS HERE: Create sample weights for each data point ***\n",
    "    emotion_sample_weights = np.array([class_weights[label] for label in y_multi_idx], dtype=np.float32)\n",
    "    stress_sample_weights = np.ones_like(y_binary, dtype=np.float32) # No special weights for stress\n",
    "    \n",
    "    indices = np.arange(len(X))\n",
    "    train_indices, temp_indices = train_test_split(indices, test_size=(test_size + val_size), random_state=random_state, stratify=y_multi_idx)\n",
    "    val_indices, test_indices = train_test_split(temp_indices, test_size=(test_size / (test_size + val_size)), random_state=random_state, stratify=y_multi_idx[temp_indices])\n",
    "\n",
    "    def make_ds(inds):\n",
    "        x = X[inds]\n",
    "        y = {'stressed_not_stressed_output': y_binary[inds], 'emotion_class_output': y_multi_onehot[inds]}\n",
    "        # Create a matching dictionary for sample weights\n",
    "        sw = {'stressed_not_stressed_output': stress_sample_weights[inds], 'emotion_class_output': emotion_sample_weights[inds]}\n",
    "        # Include sample weights as the third element\n",
    "        return tf.data.Dataset.from_tensor_slices((x, y, sw)).shuffle(len(inds), seed=random_state).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    datasets = {'train': make_ds(train_indices), 'val': make_ds(val_indices), 'test': make_ds(test_indices)}\n",
    "    meta = {'counts': {cls: labels.count(cls) for cls in CLASS_NAMES}, 'total_samples': len(X), 'class_weights': class_weights, 'index_to_class': {i: c for i, c in enumerate(CLASS_NAMES)}}\n",
    "    return datasets, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b7010",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7feedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3. Model Definition (Lighter Version)\n",
    "# ==============================================================================\n",
    "\n",
    "class Attention(Layer):\n",
    "    # ... (This class remains unchanged) ...\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1), initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1), initializer=\"zeros\")\n",
    "        super(Attention, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        et = tf.keras.backend.squeeze(tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b), axis=-1)\n",
    "        at = tf.keras.backend.softmax(et)\n",
    "        at = tf.keras.backend.expand_dims(at, axis=-1)\n",
    "        output = x * at\n",
    "        return tf.keras.backend.sum(output, axis=1)\n",
    "\n",
    "def create_eeg_model(input_shape):\n",
    "    \"\"\"Create a LIGHTER multi-output model to consume less memory.\"\"\"\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Lambda(lambda z: tf.expand_dims(z, axis=-1))(input_layer)\n",
    "    \n",
    "    # *** FIX: Reduced filters in Conv2D layers ***\n",
    "    x = TimeDistributed(Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(Conv2D(filters=4, kernel_size=(3, 3), activation='relu', padding='same'))(x)\n",
    "    \n",
    "    x = Reshape((input_shape[0], -1))(x)\n",
    "\n",
    "    # *** FIX: Reduced units in LSTM layers ***\n",
    "    x = Bidirectional(LSTM(16, return_sequences=True))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Bidirectional(LSTM(8, return_sequences=True))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    attention_output = Attention()(x)\n",
    "    main_path = GlobalAveragePooling1D()(x)\n",
    "    main_path = concatenate([main_path, attention_output])\n",
    "\n",
    "    # Binary head (Stress)\n",
    "    binary_head = Dense(16, activation='relu')(main_path) # Reduced units\n",
    "    binary_head = Dropout(0.4)(binary_head)\n",
    "    binary_head_output = Dense(1, activation='sigmoid', name='stressed_not_stressed_output')(binary_head)\n",
    "\n",
    "    # Multi-class head (Emotion)\n",
    "    multiclass_head = Dense(16, activation='relu')(main_path) # Reduced units\n",
    "    multiclass_head = Dropout(0.4)(multiclass_head)\n",
    "    multiclass_head_output = Dense(len(CLASS_NAMES), activation='softmax', name='emotion_class_output')(multiclass_head)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=input_layer,\n",
    "        outputs={\n",
    "            \"stressed_not_stressed_output\": binary_head_output,\n",
    "            \"emotion_class_output\": multiclass_head_output\n",
    "        }\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453aad36",
   "metadata": {},
   "source": [
    "### Main Execution and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee3c1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory growth configured for 1 device(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758498892.366783   99856 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5437 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>,   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">292</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5280</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">678,016</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,624</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ emotion_class_outp… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ stressed_not_stres… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m55\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m24\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m55\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m55\u001b[0m,   │         \u001b[38;5;34m80\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m8\u001b[0m)            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m55\u001b[0m,   │        \u001b[38;5;34m292\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m5280\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │    \u001b[38;5;34m678,016\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m2,624\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m144\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ emotion_class_outp… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m136\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ stressed_not_stres… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">682,365</span> (2.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m682,365\u001b[0m (2.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">682,365</span> (2.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m682,365\u001b[0m (2.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Model Training ---\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 05:25:03.523101: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1284 - emotion_class_output_loss: 2.1202 - loss: 2.4068 - stressed_not_stressed_output_accuracy: 0.7112 - stressed_not_stressed_output_loss: 0.5732\n",
      "Epoch 1: val_emotion_class_output_accuracy improved from None to 0.13889, saving model to models/best_model_20250922-052453.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 116ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.1193 - loss: 2.4060 - stressed_not_stressed_output_accuracy: 0.7229 - stressed_not_stressed_output_loss: 0.5709 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0878 - val_loss: 2.3693 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5628 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.1196 - emotion_class_output_loss: 2.1177 - loss: 2.4253 - stressed_not_stressed_output_accuracy: 0.7206 - stressed_not_stressed_output_loss: 0.6150\n",
      "Epoch 2: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1145 - emotion_class_output_loss: 2.1058 - loss: 2.4122 - stressed_not_stressed_output_accuracy: 0.7108 - stressed_not_stressed_output_loss: 0.6063 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3629 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5656 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - emotion_class_output_accuracy: 0.1085 - emotion_class_output_loss: 2.0911 - loss: 2.3851 - stressed_not_stressed_output_accuracy: 0.7656 - stressed_not_stressed_output_loss: 0.5880\n",
      "Epoch 3: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - emotion_class_output_accuracy: 0.1386 - emotion_class_output_loss: 2.0822 - loss: 2.3808 - stressed_not_stressed_output_accuracy: 0.7410 - stressed_not_stressed_output_loss: 0.6000 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0821 - val_loss: 2.3633 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.0683 - emotion_class_output_loss: 2.0952 - loss: 2.3887 - stressed_not_stressed_output_accuracy: 0.7228 - stressed_not_stressed_output_loss: 0.5870\n",
      "Epoch 4: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.0783 - emotion_class_output_loss: 2.0891 - loss: 2.3714 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5588 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3613 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5632 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1032 - emotion_class_output_loss: 2.0717 - loss: 2.3727 - stressed_not_stressed_output_accuracy: 0.7226 - stressed_not_stressed_output_loss: 0.6021\n",
      "Epoch 5: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0841 - loss: 2.3838 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5986 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0802 - val_loss: 2.3614 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1268 - emotion_class_output_loss: 2.0778 - loss: 2.3727 - stressed_not_stressed_output_accuracy: 0.7525 - stressed_not_stressed_output_loss: 0.5896\n",
      "Epoch 6: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0787 - loss: 2.3674 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5747 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0813 - val_loss: 2.3624 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.0863 - emotion_class_output_loss: 2.0921 - loss: 2.3752 - stressed_not_stressed_output_accuracy: 0.7587 - stressed_not_stressed_output_loss: 0.5662\n",
      "Epoch 7: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1145 - emotion_class_output_loss: 2.0914 - loss: 2.3871 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.6016 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0808 - val_loss: 2.3621 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5627 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.0642 - emotion_class_output_loss: 2.0903 - loss: 2.3588 - stressed_not_stressed_output_accuracy: 0.7739 - stressed_not_stressed_output_loss: 0.5371\n",
      "Epoch 8: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.0904 - emotion_class_output_loss: 2.0828 - loss: 2.3633 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5637 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0794 - val_loss: 2.3606 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1884 - emotion_class_output_loss: 2.0724 - loss: 2.3644 - stressed_not_stressed_output_accuracy: 0.7388 - stressed_not_stressed_output_loss: 0.5840\n",
      "Epoch 9: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1446 - emotion_class_output_loss: 2.0816 - loss: 2.3737 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5820 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.1245 - emotion_class_output_loss: 2.0762 - loss: 2.3703 - stressed_not_stressed_output_accuracy: 0.7474 - stressed_not_stressed_output_loss: 0.5883\n",
      "Epoch 10: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0762 - loss: 2.3686 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5809 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0792 - val_loss: 2.3604 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1161 - emotion_class_output_loss: 2.0870 - loss: 2.3591 - stressed_not_stressed_output_accuracy: 0.7920 - stressed_not_stressed_output_loss: 0.5442\n",
      "Epoch 11: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0839 - loss: 2.3790 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5887 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3610 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1638 - emotion_class_output_loss: 2.0771 - loss: 2.3628 - stressed_not_stressed_output_accuracy: 0.7414 - stressed_not_stressed_output_loss: 0.5715\n",
      "Epoch 12: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1386 - emotion_class_output_loss: 2.0808 - loss: 2.3657 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5761 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3613 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5632 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1487 - emotion_class_output_loss: 2.0839 - loss: 2.3384 - stressed_not_stressed_output_accuracy: 0.7990 - stressed_not_stressed_output_loss: 0.5090\n",
      "Epoch 13: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0796 - loss: 2.3650 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5710 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3614 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5630 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1045 - emotion_class_output_loss: 2.0835 - loss: 2.3817 - stressed_not_stressed_output_accuracy: 0.7282 - stressed_not_stressed_output_loss: 0.5964\n",
      "Epoch 14: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0793 - loss: 2.3733 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5838 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0800 - val_loss: 2.3619 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5638 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1145 - emotion_class_output_loss: 2.0839 - loss: 2.3551 - stressed_not_stressed_output_accuracy: 0.7895 - stressed_not_stressed_output_loss: 0.5424\n",
      "Epoch 15: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1145 - emotion_class_output_loss: 2.0780 - loss: 2.3678 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5830 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0800 - val_loss: 2.3612 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.1182 - emotion_class_output_loss: 2.0839 - loss: 2.3788 - stressed_not_stressed_output_accuracy: 0.7469 - stressed_not_stressed_output_loss: 0.5897\n",
      "Epoch 16: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1145 - emotion_class_output_loss: 2.0771 - loss: 2.3703 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5824 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3614 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5630 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.0908 - emotion_class_output_loss: 2.0824 - loss: 2.3814 - stressed_not_stressed_output_accuracy: 0.7162 - stressed_not_stressed_output_loss: 0.5980\n",
      "Epoch 17: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.0904 - emotion_class_output_loss: 2.0797 - loss: 2.3678 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5774 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0803 - val_loss: 2.3615 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1345 - emotion_class_output_loss: 2.0828 - loss: 2.3578 - stressed_not_stressed_output_accuracy: 0.7705 - stressed_not_stressed_output_loss: 0.5501\n",
      "Epoch 18: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1205 - emotion_class_output_loss: 2.0774 - loss: 2.3615 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5737 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3613 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.0881 - emotion_class_output_loss: 2.0677 - loss: 2.3676 - stressed_not_stressed_output_accuracy: 0.7107 - stressed_not_stressed_output_loss: 0.5999\n",
      "Epoch 19: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.0723 - emotion_class_output_loss: 2.0761 - loss: 2.3630 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5719 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0802 - val_loss: 2.3615 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.0924 - emotion_class_output_loss: 2.0753 - loss: 2.3601 - stressed_not_stressed_output_accuracy: 0.7417 - stressed_not_stressed_output_loss: 0.5696\n",
      "Epoch 20: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0751 - loss: 2.3557 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5591 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3613 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1326 - emotion_class_output_loss: 2.0645 - loss: 2.3353 - stressed_not_stressed_output_accuracy: 0.7683 - stressed_not_stressed_output_loss: 0.5415\n",
      "Epoch 21: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1205 - emotion_class_output_loss: 2.0743 - loss: 2.3671 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5889 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0802 - val_loss: 2.3615 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1259 - emotion_class_output_loss: 2.0747 - loss: 2.3946 - stressed_not_stressed_output_accuracy: 0.6766 - stressed_not_stressed_output_loss: 0.6398\n",
      "Epoch 22: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1024 - emotion_class_output_loss: 2.0741 - loss: 2.3609 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5715 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0802 - val_loss: 2.3615 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1660 - emotion_class_output_loss: 2.0685 - loss: 2.3592 - stressed_not_stressed_output_accuracy: 0.7698 - stressed_not_stressed_output_loss: 0.5813\n",
      "Epoch 23: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1386 - emotion_class_output_loss: 2.0757 - loss: 2.3642 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5836 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0802 - val_loss: 2.3615 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.0910 - emotion_class_output_loss: 2.0472 - loss: 2.3245 - stressed_not_stressed_output_accuracy: 0.7708 - stressed_not_stressed_output_loss: 0.5546\n",
      "Epoch 24: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.0843 - emotion_class_output_loss: 2.0772 - loss: 2.3646 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5763 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0831 - val_loss: 2.3649 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5636 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1389 - emotion_class_output_loss: 2.0904 - loss: 2.3685 - stressed_not_stressed_output_accuracy: 0.7773 - stressed_not_stressed_output_loss: 0.5562\n",
      "Epoch 25: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0804 - loss: 2.3687 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5734 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3616 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5630 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1408 - emotion_class_output_loss: 2.0366 - loss: 2.3748 - stressed_not_stressed_output_accuracy: 0.6434 - stressed_not_stressed_output_loss: 0.6764\n",
      "Epoch 26: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0719 - loss: 2.3598 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5748 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3614 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1188 - emotion_class_output_loss: 2.0779 - loss: 2.3870 - stressed_not_stressed_output_accuracy: 0.7137 - stressed_not_stressed_output_loss: 0.6181\n",
      "Epoch 27: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1024 - emotion_class_output_loss: 2.0707 - loss: 2.3611 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5779 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3614 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1417 - emotion_class_output_loss: 2.0679 - loss: 2.3656 - stressed_not_stressed_output_accuracy: 0.7264 - stressed_not_stressed_output_loss: 0.5953\n",
      "Epoch 28: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0694 - loss: 2.3561 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5703 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0802 - val_loss: 2.3614 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1093 - emotion_class_output_loss: 2.0691 - loss: 2.3577 - stressed_not_stressed_output_accuracy: 0.7510 - stressed_not_stressed_output_loss: 0.5771\n",
      "Epoch 29: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1024 - emotion_class_output_loss: 2.0702 - loss: 2.3557 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5795 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3614 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1173 - emotion_class_output_loss: 2.0732 - loss: 2.3576 - stressed_not_stressed_output_accuracy: 0.7441 - stressed_not_stressed_output_loss: 0.5689\n",
      "Epoch 30: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0684 - loss: 2.3532 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5778 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0802 - val_loss: 2.3615 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1240 - emotion_class_output_loss: 2.0693 - loss: 2.3564 - stressed_not_stressed_output_accuracy: 0.7649 - stressed_not_stressed_output_loss: 0.5743\n",
      "Epoch 31: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1205 - emotion_class_output_loss: 2.0688 - loss: 2.3587 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5884 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0800 - val_loss: 2.3613 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1065 - emotion_class_output_loss: 2.0804 - loss: 2.3725 - stressed_not_stressed_output_accuracy: 0.7334 - stressed_not_stressed_output_loss: 0.5842\n",
      "Epoch 32: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.0843 - emotion_class_output_loss: 2.0767 - loss: 2.3575 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5594 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0802 - val_loss: 2.3613 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1345 - emotion_class_output_loss: 2.0773 - loss: 2.3478 - stressed_not_stressed_output_accuracy: 0.7714 - stressed_not_stressed_output_loss: 0.5409\n",
      "Epoch 33: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1145 - emotion_class_output_loss: 2.0681 - loss: 2.3482 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5576 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3612 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.0878 - emotion_class_output_loss: 2.0764 - loss: 2.3597 - stressed_not_stressed_output_accuracy: 0.7574 - stressed_not_stressed_output_loss: 0.5665\n",
      "Epoch 34: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1024 - emotion_class_output_loss: 2.0706 - loss: 2.3554 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5736 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3618 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5634 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1448 - emotion_class_output_loss: 2.0571 - loss: 2.3542 - stressed_not_stressed_output_accuracy: 0.7236 - stressed_not_stressed_output_loss: 0.5941\n",
      "Epoch 35: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0698 - loss: 2.3512 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5620 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3612 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1222 - emotion_class_output_loss: 2.0683 - loss: 2.3371 - stressed_not_stressed_output_accuracy: 0.7589 - stressed_not_stressed_output_loss: 0.5376\n",
      "Epoch 36: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.0964 - emotion_class_output_loss: 2.0673 - loss: 2.3418 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5518 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0800 - val_loss: 2.3619 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5639 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1593 - emotion_class_output_loss: 2.0806 - loss: 2.3509 - stressed_not_stressed_output_accuracy: 0.7656 - stressed_not_stressed_output_loss: 0.5406\n",
      "Epoch 37: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0676 - loss: 2.3548 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5729 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3611 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.1415 - emotion_class_output_loss: 2.0803 - loss: 2.3191 - stressed_not_stressed_output_accuracy: 0.8192 - stressed_not_stressed_output_loss: 0.4776\n",
      "Epoch 38: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0791 - loss: 2.3592 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5649 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3613 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5628 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1628 - emotion_class_output_loss: 2.0758 - loss: 2.3371 - stressed_not_stressed_output_accuracy: 0.7742 - stressed_not_stressed_output_loss: 0.5226\n",
      "Epoch 39: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0731 - loss: 2.3502 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5504 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3614 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5627 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1378 - emotion_class_output_loss: 2.0798 - loss: 2.3410 - stressed_not_stressed_output_accuracy: 0.7912 - stressed_not_stressed_output_loss: 0.5224\n",
      "Epoch 40: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1145 - emotion_class_output_loss: 2.0716 - loss: 2.3560 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5729 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3612 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1777 - emotion_class_output_loss: 2.0651 - loss: 2.3896 - stressed_not_stressed_output_accuracy: 0.7062 - stressed_not_stressed_output_loss: 0.6489\n",
      "Epoch 41: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1446 - emotion_class_output_loss: 2.0629 - loss: 2.3687 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.6097 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0825 - val_loss: 2.3657 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5663 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.2110 - emotion_class_output_loss: 2.0618 - loss: 2.3381 - stressed_not_stressed_output_accuracy: 0.7541 - stressed_not_stressed_output_loss: 0.5526\n",
      "Epoch 42: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1807 - emotion_class_output_loss: 2.0721 - loss: 2.3516 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5559 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3614 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5630 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1026 - emotion_class_output_loss: 2.0638 - loss: 2.3638 - stressed_not_stressed_output_accuracy: 0.7402 - stressed_not_stressed_output_loss: 0.6000\n",
      "Epoch 43: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0672 - loss: 2.3622 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5866 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3613 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5629 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1502 - emotion_class_output_loss: 2.0676 - loss: 2.3288 - stressed_not_stressed_output_accuracy: 0.8078 - stressed_not_stressed_output_loss: 0.5223\n",
      "Epoch 44: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0718 - loss: 2.3648 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5838 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0800 - val_loss: 2.3635 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5670 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1353 - emotion_class_output_loss: 2.0844 - loss: 2.3899 - stressed_not_stressed_output_accuracy: 0.7150 - stressed_not_stressed_output_loss: 0.6111\n",
      "Epoch 45: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.0904 - emotion_class_output_loss: 2.0879 - loss: 2.3791 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5798 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3616 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5633 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1546 - emotion_class_output_loss: 2.0666 - loss: 2.3347 - stressed_not_stressed_output_accuracy: 0.7618 - stressed_not_stressed_output_loss: 0.5362\n",
      "Epoch 46: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0772 - loss: 2.3576 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5580 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0810 - val_loss: 2.3635 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5650 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1222 - emotion_class_output_loss: 2.0856 - loss: 2.3828 - stressed_not_stressed_output_accuracy: 0.7264 - stressed_not_stressed_output_loss: 0.5945\n",
      "Epoch 47: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1205 - emotion_class_output_loss: 2.0715 - loss: 2.3589 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5728 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3622 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5643 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1353 - emotion_class_output_loss: 2.0594 - loss: 2.3129 - stressed_not_stressed_output_accuracy: 0.8131 - stressed_not_stressed_output_loss: 0.5069\n",
      "Epoch 48: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0674 - loss: 2.3581 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5790 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0801 - val_loss: 2.3614 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5627 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - emotion_class_output_accuracy: 0.1202 - emotion_class_output_loss: 2.0266 - loss: 2.3008 - stressed_not_stressed_output_accuracy: 0.7697 - stressed_not_stressed_output_loss: 0.5485\n",
      "Epoch 49: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.0783 - emotion_class_output_loss: 2.0676 - loss: 2.3514 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5661 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3613 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5628 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1199 - emotion_class_output_loss: 2.0756 - loss: 2.3596 - stressed_not_stressed_output_accuracy: 0.7482 - stressed_not_stressed_output_loss: 0.5681\n",
      "Epoch 50: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0684 - loss: 2.3527 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5665 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0800 - val_loss: 2.3613 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1086 - emotion_class_output_loss: 2.0529 - loss: 2.3137 - stressed_not_stressed_output_accuracy: 0.7818 - stressed_not_stressed_output_loss: 0.5215\n",
      "Epoch 51: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.0904 - emotion_class_output_loss: 2.0672 - loss: 2.3511 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5710 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3611 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1271 - emotion_class_output_loss: 2.0515 - loss: 2.3373 - stressed_not_stressed_output_accuracy: 0.7433 - stressed_not_stressed_output_loss: 0.5717\n",
      "Epoch 52: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1145 - emotion_class_output_loss: 2.0673 - loss: 2.3600 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5891 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3620 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5643 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1597 - emotion_class_output_loss: 2.0784 - loss: 2.3694 - stressed_not_stressed_output_accuracy: 0.7339 - stressed_not_stressed_output_loss: 0.5820\n",
      "Epoch 53: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0718 - loss: 2.3558 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5647 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3611 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1821 - emotion_class_output_loss: 2.0714 - loss: 2.3266 - stressed_not_stressed_output_accuracy: 0.8038 - stressed_not_stressed_output_loss: 0.5104\n",
      "Epoch 54: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0669 - loss: 2.3535 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5764 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3612 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.0810 - emotion_class_output_loss: 2.0807 - loss: 2.3601 - stressed_not_stressed_output_accuracy: 0.7608 - stressed_not_stressed_output_loss: 0.5581\n",
      "Epoch 55: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.0843 - emotion_class_output_loss: 2.0553 - loss: 2.3477 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5578 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3611 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1810 - emotion_class_output_loss: 2.0594 - loss: 2.3506 - stressed_not_stressed_output_accuracy: 0.7142 - stressed_not_stressed_output_loss: 0.5825\n",
      "Epoch 56: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0700 - loss: 2.3492 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5549 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0800 - val_loss: 2.3613 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1389 - emotion_class_output_loss: 2.0786 - loss: 2.3270 - stressed_not_stressed_output_accuracy: 0.8078 - stressed_not_stressed_output_loss: 0.4968\n",
      "Epoch 57: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0714 - loss: 2.3589 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5784 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3610 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1262 - emotion_class_output_loss: 2.0727 - loss: 2.3412 - stressed_not_stressed_output_accuracy: 0.7686 - stressed_not_stressed_output_loss: 0.5372\n",
      "Epoch 58: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1145 - emotion_class_output_loss: 2.0679 - loss: 2.3457 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5588 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3610 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1377 - emotion_class_output_loss: 2.0744 - loss: 2.3621 - stressed_not_stressed_output_accuracy: 0.7425 - stressed_not_stressed_output_loss: 0.5754\n",
      "Epoch 59: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0672 - loss: 2.3469 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5613 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0798 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1535 - emotion_class_output_loss: 2.0661 - loss: 2.3271 - stressed_not_stressed_output_accuracy: 0.7878 - stressed_not_stressed_output_loss: 0.5220\n",
      "Epoch 60: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0674 - loss: 2.3553 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5780 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1622 - emotion_class_output_loss: 2.0774 - loss: 2.3619 - stressed_not_stressed_output_accuracy: 0.7292 - stressed_not_stressed_output_loss: 0.5690\n",
      "Epoch 61: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0756 - loss: 2.3541 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5532 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1241 - emotion_class_output_loss: 2.0738 - loss: 2.3593 - stressed_not_stressed_output_accuracy: 0.7532 - stressed_not_stressed_output_loss: 0.5712\n",
      "Epoch 62: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1024 - emotion_class_output_loss: 2.0761 - loss: 2.3591 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5633 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3611 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1682 - emotion_class_output_loss: 2.0772 - loss: 2.3488 - stressed_not_stressed_output_accuracy: 0.7802 - stressed_not_stressed_output_loss: 0.5432\n",
      "Epoch 63: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0690 - loss: 2.3518 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5623 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3611 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1476 - emotion_class_output_loss: 2.0775 - loss: 2.3322 - stressed_not_stressed_output_accuracy: 0.8120 - stressed_not_stressed_output_loss: 0.5093\n",
      "Epoch 64: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0689 - loss: 2.3594 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5835 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0798 - val_loss: 2.3617 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5636 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.1279 - emotion_class_output_loss: 2.0595 - loss: 2.3379 - stressed_not_stressed_output_accuracy: 0.7535 - stressed_not_stressed_output_loss: 0.5568\n",
      "Epoch 65: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0673 - loss: 2.3481 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5589 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0796 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.1374 - emotion_class_output_loss: 2.0508 - loss: 2.3433 - stressed_not_stressed_output_accuracy: 0.7274 - stressed_not_stressed_output_loss: 0.5851\n",
      "Epoch 66: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1205 - emotion_class_output_loss: 2.0678 - loss: 2.3522 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5734 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.1629 - emotion_class_output_loss: 2.0389 - loss: 2.3436 - stressed_not_stressed_output_accuracy: 0.7232 - stressed_not_stressed_output_loss: 0.6093\n",
      "Epoch 67: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0674 - loss: 2.3578 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5892 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0799 - val_loss: 2.3610 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1539 - emotion_class_output_loss: 2.0762 - loss: 2.3621 - stressed_not_stressed_output_accuracy: 0.7421 - stressed_not_stressed_output_loss: 0.5718\n",
      "Epoch 68: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0671 - loss: 2.3509 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5712 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0798 - val_loss: 2.3610 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1459 - emotion_class_output_loss: 2.0791 - loss: 2.3370 - stressed_not_stressed_output_accuracy: 0.7801 - stressed_not_stressed_output_loss: 0.5158\n",
      "Epoch 69: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0676 - loss: 2.3433 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5484 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3610 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1480 - emotion_class_output_loss: 2.0506 - loss: 2.3377 - stressed_not_stressed_output_accuracy: 0.7487 - stressed_not_stressed_output_loss: 0.5741\n",
      "Epoch 70: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0674 - loss: 2.3494 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5722 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3608 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.0984 - emotion_class_output_loss: 2.0760 - loss: 2.3596 - stressed_not_stressed_output_accuracy: 0.7491 - stressed_not_stressed_output_loss: 0.5672\n",
      "Epoch 71: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1024 - emotion_class_output_loss: 2.0674 - loss: 2.3549 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5740 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.1192 - emotion_class_output_loss: 2.0793 - loss: 2.3632 - stressed_not_stressed_output_accuracy: 0.7554 - stressed_not_stressed_output_loss: 0.5678\n",
      "Epoch 72: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1205 - emotion_class_output_loss: 2.0687 - loss: 2.3539 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5732 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0798 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.1769 - emotion_class_output_loss: 2.0444 - loss: 2.3031 - stressed_not_stressed_output_accuracy: 0.7972 - stressed_not_stressed_output_loss: 0.5172\n",
      "Epoch 73: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0676 - loss: 2.3505 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5693 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0798 - val_loss: 2.3610 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1185 - emotion_class_output_loss: 2.0781 - loss: 2.3211 - stressed_not_stressed_output_accuracy: 0.8187 - stressed_not_stressed_output_loss: 0.4861\n",
      "Epoch 74: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0677 - loss: 2.3461 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5584 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0796 - val_loss: 2.3608 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1233 - emotion_class_output_loss: 2.0435 - loss: 2.3215 - stressed_not_stressed_output_accuracy: 0.7354 - stressed_not_stressed_output_loss: 0.5560\n",
      "Epoch 75: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1024 - emotion_class_output_loss: 2.0674 - loss: 2.3455 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5598 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0798 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.0921 - emotion_class_output_loss: 2.0607 - loss: 2.3384 - stressed_not_stressed_output_accuracy: 0.7565 - stressed_not_stressed_output_loss: 0.5552\n",
      "Epoch 76: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0675 - loss: 2.3493 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5722 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1928 - emotion_class_output_loss: 2.0243 - loss: 2.3016 - stressed_not_stressed_output_accuracy: 0.7591 - stressed_not_stressed_output_loss: 0.5549\n",
      "Epoch 77: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0671 - loss: 2.3485 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5738 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1374 - emotion_class_output_loss: 2.0553 - loss: 2.3359 - stressed_not_stressed_output_accuracy: 0.7538 - stressed_not_stressed_output_loss: 0.5612\n",
      "Epoch 78: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0669 - loss: 2.3510 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5714 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0798 - val_loss: 2.3613 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5631 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1324 - emotion_class_output_loss: 2.0798 - loss: 2.3707 - stressed_not_stressed_output_accuracy: 0.7258 - stressed_not_stressed_output_loss: 0.5818\n",
      "Epoch 79: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0675 - loss: 2.3484 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5595 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0796 - val_loss: 2.3608 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.0937 - emotion_class_output_loss: 2.0445 - loss: 2.3097 - stressed_not_stressed_output_accuracy: 0.7754 - stressed_not_stressed_output_loss: 0.5304\n",
      "Epoch 80: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0671 - loss: 2.3475 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5637 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1032 - emotion_class_output_loss: 2.0846 - loss: 2.3569 - stressed_not_stressed_output_accuracy: 0.7819 - stressed_not_stressed_output_loss: 0.5447\n",
      "Epoch 81: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1024 - emotion_class_output_loss: 2.0673 - loss: 2.3583 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5829 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0796 - val_loss: 2.3626 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5658 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - emotion_class_output_accuracy: 0.0697 - emotion_class_output_loss: 2.0798 - loss: 2.3336 - stressed_not_stressed_output_accuracy: 0.8316 - stressed_not_stressed_output_loss: 0.5077\n",
      "Epoch 82: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.1024 - emotion_class_output_loss: 2.0687 - loss: 2.3575 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5791 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3610 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.0800 - emotion_class_output_loss: 2.0688 - loss: 2.3656 - stressed_not_stressed_output_accuracy: 0.7277 - stressed_not_stressed_output_loss: 0.5935\n",
      "Epoch 83: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0670 - loss: 2.3467 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5558 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0796 - val_loss: 2.3608 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1439 - emotion_class_output_loss: 2.0739 - loss: 2.3770 - stressed_not_stressed_output_accuracy: 0.7208 - stressed_not_stressed_output_loss: 0.6060\n",
      "Epoch 84: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0672 - loss: 2.3580 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5856 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.0677 - emotion_class_output_loss: 2.0746 - loss: 2.3184 - stressed_not_stressed_output_accuracy: 0.8093 - stressed_not_stressed_output_loss: 0.4875\n",
      "Epoch 85: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - emotion_class_output_accuracy: 0.0964 - emotion_class_output_loss: 2.0681 - loss: 2.3477 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5570 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3608 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - emotion_class_output_accuracy: 0.0784 - emotion_class_output_loss: 2.0801 - loss: 2.3483 - stressed_not_stressed_output_accuracy: 0.7760 - stressed_not_stressed_output_loss: 0.5364\n",
      "Epoch 86: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - emotion_class_output_accuracy: 0.1084 - emotion_class_output_loss: 2.0671 - loss: 2.3531 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5752 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1097 - emotion_class_output_loss: 2.0771 - loss: 2.3804 - stressed_not_stressed_output_accuracy: 0.7247 - stressed_not_stressed_output_loss: 0.6067\n",
      "Epoch 87: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0675 - loss: 2.3497 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5626 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0795 - val_loss: 2.3611 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5632 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1076 - emotion_class_output_loss: 2.0734 - loss: 2.3592 - stressed_not_stressed_output_accuracy: 0.7573 - stressed_not_stressed_output_loss: 0.5717\n",
      "Epoch 88: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1145 - emotion_class_output_loss: 2.0676 - loss: 2.3575 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5768 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0796 - val_loss: 2.3610 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1207 - emotion_class_output_loss: 2.0691 - loss: 2.3393 - stressed_not_stressed_output_accuracy: 0.7784 - stressed_not_stressed_output_loss: 0.5404\n",
      "Epoch 89: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1024 - emotion_class_output_loss: 2.0671 - loss: 2.3510 - stressed_not_stressed_output_accuracy: 0.7470 - stressed_not_stressed_output_loss: 0.5645 - val_emotion_class_output_accuracy: 0.1111 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1183 - emotion_class_output_loss: 2.0665 - loss: 2.3548 - stressed_not_stressed_output_accuracy: 0.7226 - stressed_not_stressed_output_loss: 0.5767\n",
      "Epoch 90: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0673 - loss: 2.3479 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5643 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0796 - val_loss: 2.3608 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1333 - emotion_class_output_loss: 2.0626 - loss: 2.3322 - stressed_not_stressed_output_accuracy: 0.7695 - stressed_not_stressed_output_loss: 0.5393\n",
      "Epoch 91: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1145 - emotion_class_output_loss: 2.0670 - loss: 2.3470 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5703 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0795 - val_loss: 2.3607 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1917 - emotion_class_output_loss: 2.0711 - loss: 2.3877 - stressed_not_stressed_output_accuracy: 0.6972 - stressed_not_stressed_output_loss: 0.6333\n",
      "Epoch 92: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0671 - loss: 2.3525 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5737 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0795 - val_loss: 2.3608 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - emotion_class_output_accuracy: 0.1682 - emotion_class_output_loss: 2.0773 - loss: 2.3556 - stressed_not_stressed_output_accuracy: 0.7553 - stressed_not_stressed_output_loss: 0.5567\n",
      "Epoch 93: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0670 - loss: 2.3476 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5584 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0796 - val_loss: 2.3608 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1160 - emotion_class_output_loss: 2.0690 - loss: 2.3665 - stressed_not_stressed_output_accuracy: 0.7264 - stressed_not_stressed_output_loss: 0.5950\n",
      "Epoch 94: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0671 - loss: 2.3518 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5740 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0797 - val_loss: 2.3608 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - emotion_class_output_accuracy: 0.0994 - emotion_class_output_loss: 2.0787 - loss: 2.3533 - stressed_not_stressed_output_accuracy: 0.7542 - stressed_not_stressed_output_loss: 0.5492\n",
      "Epoch 95: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0675 - loss: 2.3466 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5558 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0796 - val_loss: 2.3608 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1761 - emotion_class_output_loss: 2.0688 - loss: 2.3794 - stressed_not_stressed_output_accuracy: 0.7125 - stressed_not_stressed_output_loss: 0.6212\n",
      "Epoch 96: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0675 - loss: 2.3530 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5681 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0795 - val_loss: 2.3607 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0623 - loss: 2.3426 - stressed_not_stressed_output_accuracy: 0.7434 - stressed_not_stressed_output_loss: 0.5607\n",
      "Epoch 97: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - emotion_class_output_accuracy: 0.0964 - emotion_class_output_loss: 2.0673 - loss: 2.3468 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5720 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0796 - val_loss: 2.3611 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5631 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1164 - emotion_class_output_loss: 2.0576 - loss: 2.3399 - stressed_not_stressed_output_accuracy: 0.7518 - stressed_not_stressed_output_loss: 0.5645\n",
      "Epoch 98: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0674 - loss: 2.3501 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5635 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0795 - val_loss: 2.3609 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5628 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - emotion_class_output_accuracy: 0.1457 - emotion_class_output_loss: 2.0699 - loss: 2.3250 - stressed_not_stressed_output_accuracy: 0.8034 - stressed_not_stressed_output_loss: 0.5103\n",
      "Epoch 99: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - emotion_class_output_accuracy: 0.1325 - emotion_class_output_loss: 2.0679 - loss: 2.3502 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5733 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0794 - val_loss: 2.3605 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5623 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - emotion_class_output_accuracy: 0.1422 - emotion_class_output_loss: 2.0736 - loss: 2.3613 - stressed_not_stressed_output_accuracy: 0.7345 - stressed_not_stressed_output_loss: 0.5755\n",
      "Epoch 100: val_emotion_class_output_accuracy did not improve from 0.13889\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - emotion_class_output_accuracy: 0.1265 - emotion_class_output_loss: 2.0732 - loss: 2.3526 - stressed_not_stressed_output_accuracy: 0.7530 - stressed_not_stressed_output_loss: 0.5561 - val_emotion_class_output_accuracy: 0.1389 - val_emotion_class_output_loss: 2.0795 - val_loss: 2.3607 - val_stressed_not_stressed_output_accuracy: 0.7500 - val_stressed_not_stressed_output_loss: 0.5624 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "--- Evaluating Model on Test Set ---\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - emotion_class_output_accuracy: 0.1111 - emotion_class_output_loss: 2.0875 - loss: 2.3693 - stressed_not_stressed_output_accuracy: 0.7500 - stressed_not_stressed_output_loss: 0.5636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  loss: 2.3693\n",
      "  compile_metrics: 0.5636\n",
      "  stressed_not_stressed_output_loss: 2.0875\n",
      "  emotion_class_output_loss: 0.1111\n",
      "\n",
      "Final model and metadata saved with timestamp: 20250922-052453\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 4. Main Execution Block (Corrected Callbacks)\n",
    "# ==============================================================================\n",
    "if __name__ == '__main__':\n",
    "    # Add the GPU configuration from the previous step here\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"GPU memory growth configured for {len(gpus)} device(s).\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "    dataset_path = \"/media/kd/New Volume/Github/EEG-Emotion-Detection/dataset\"\n",
    "    \n",
    "    INPUT_TIME_STEPS = 128\n",
    "    INPUT_CHANNELS = 55\n",
    "    INPUT_FEATURES = 24\n",
    "    INPUT_3D_SHAPE = (INPUT_TIME_STEPS, INPUT_CHANNELS, INPUT_FEATURES)\n",
    "\n",
    "    # Use the smaller batch size\n",
    "    datasets, meta = load_eeg_dataset(\n",
    "        dataset_path,\n",
    "        time_steps=INPUT_TIME_STEPS,\n",
    "        channels=INPUT_CHANNELS,\n",
    "        features=INPUT_FEATURES,\n",
    "        batch_size=4 \n",
    "    )\n",
    "\n",
    "    # Use the lighter model\n",
    "    model = create_eeg_model(INPUT_3D_SHAPE)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss={'stressed_not_stressed_output': 'binary_crossentropy', 'emotion_class_output': 'categorical_crossentropy'},\n",
    "        loss_weights={'stressed_not_stressed_output': 0.5, 'emotion_class_output': 1.0},\n",
    "        metrics={'stressed_not_stressed_output': 'accuracy', 'emotion_class_output': 'accuracy'}\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    # *** FIX IS HERE: Added mode='max' to EarlyStopping and ReduceLROnPlateau ***\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            filepath=f'models/best_model_{timestamp}.h5', \n",
    "            monitor='val_emotion_class_output_accuracy', \n",
    "            save_best_only=True, \n",
    "            mode='max', # This was already correct\n",
    "            verbose=1\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_emotion_class_output_accuracy', \n",
    "            patience=100, \n",
    "            restore_best_weights=True, \n",
    "            mode='max', # Added this\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_emotion_class_output_accuracy', \n",
    "            factor=0.5, \n",
    "            patience=100, \n",
    "            min_lr=1e-6, \n",
    "            mode='max', # Added this\n",
    "            verbose=1\n",
    "        ),\n",
    "        TensorBoard(log_dir=f'logs/fit/{timestamp}', histogram_freq=1)\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Starting Model Training ---\")\n",
    "    history = model.fit(\n",
    "        datasets['train'],\n",
    "        validation_data=datasets['val'],\n",
    "        epochs=100,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Evaluating Model on Test Set ---\")\n",
    "    if datasets['test']:\n",
    "        results = model.evaluate(datasets['test'], verbose=1)\n",
    "        for name, value in zip(model.metrics_names, results):\n",
    "            print(f\"  {name}: {value:.4f}\")\n",
    "\n",
    "    model.save(f'models/final_model_{timestamp}.h5')\n",
    "    with open(f'models/model_metadata_{timestamp}.json', 'w') as f:\n",
    "        json.dump(meta, f, indent=4)\n",
    "    print(f\"\\nFinal model and metadata saved with timestamp: {timestamp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
